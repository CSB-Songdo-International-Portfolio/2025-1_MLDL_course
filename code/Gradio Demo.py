# pip install transformers torch gradio
# ì—ëŸ¬ë‚˜ë©´ accelerate ì„¤ì¹˜

import gradio as gr
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig

# ëª¨ë¸ ì´ë¦„
model_name = "Qwen/Qwen3-0.6B"

# ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸°
tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16,
    device_map="auto",
    trust_remote_code=True
)
model.eval()

# ì±„íŒ… íˆìŠ¤í† ë¦¬ ì €ì¥
chat_history = []

# ì¶”ë¡  í•¨ìˆ˜
def predict(user_input, history_display):
    global chat_history

    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    chat_history.append({"role": "user", "content": user_input})

    # ì±„íŒ… í…œí”Œë¦¿ ì ìš©
    prompt = tokenizer.apply_chat_template(
        chat_history,
        tokenize=False,
        add_generation_prompt=True
    )

    # í† í¬ë‚˜ì´ì¦ˆ
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)

    # ìƒì„± ì„¤ì •
    generation_config = GenerationConfig(
        temperature=0.7,
        top_p=0.9,
        do_sample=True,
        max_new_tokens=512
    )

    # ì‘ë‹µ ìƒì„±
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            generation_config=generation_config
        )

    # ì¶œë ¥ ë””ì½”ë”©
    output_text = tokenizer.decode(outputs[0][inputs.input_ids.shape[-1]:], skip_special_tokens=True)
    output_text = output_text.strip()

    # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ì €ì¥
    chat_history.append({"role": "assistant", "content": output_text})

    # Gradioì— í‘œì‹œí•  íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
    history_display.append((user_input, output_text))
    return "", history_display

# Gradio ì¸í„°í˜ì´ìŠ¤ êµ¬ì„±
with gr.Blocks(title="Qwen 0.6B Chatbot") as demo:
    gr.Markdown("## ğŸ¤– Qwen 0.6B Chatbot (powered by Gradio)")
    chatbot = gr.Chatbot()
    msg = gr.Textbox(label="ì…ë ¥", placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...", lines=1)
    clear = gr.Button("ì´ˆê¸°í™”")

    # ì…ë ¥ ì œì¶œ ì´ë²¤íŠ¸
    msg.submit(predict, [msg, chatbot], [msg, chatbot])
    clear.click(lambda: ([], []), None, [chatbot])

# ì•± ì‹¤í–‰
if __name__ == "__main__":
    demo.launch()
